import datetime

from django.conf import settings

from ebdata.retrieval.scrapers.newsitem_list_detail import NewsItemListDetailScraper
from ebpub.db.models import NewsItem

from gdata.spreadsheet.service import SpreadsheetsService


class GoogleScraperException(Exception):
    pass


class GoogleSpreadsheetScraper(NewsItemListDetailScraper):
    """Uses the gdata library to scrape data from a Google Spreadsheet.

    Subclasses are required to set the 'spreadsheet_id' attribute.
    """
    # Scraper settings.
    has_detail = False

    # Google Spreadsheet settings.
    username = getattr(settings, 'GOOGLE_USERNAME', None)
    password = getattr(settings, 'GOOGLE_PASSWORD', None)
    spreadsheet_id = None  # Required - the id of the spreadsheet to scrape.
    worksheet_id = 'default'  # Optional - The id of the worksheet to scrape.
    attribute_names = ()  # Names of attribute fields.
    match_names = ()  # Names of fields which determine if a record already
                      # exists.

    def __init__(self, *args, **kwargs):
        self._connected = False

        if not all((self.username, self.password, self.spreadsheet_id,
                self.worksheet_id)):
            raise GoogleScraperException('Subclasses must specify '
                    'spreadsheet_id.')

        self._connect(username=self.username, password=self.password)
        super(GoogleSpreadsheetScraper, self).__init__(*args, **kwargs)

    def _connect(self, username=None, password=None):
        username = username or self.username
        password = password or self.password
        self._connected = False
        self._client = SpreadsheetsService()
        try:
            self._client.ClientLogin(username, password)
        except:
            raise GoogleScraperException('There was an error in connecting.')
        else:
            self._connected = True

    def _get_attributes(self, list_record):
        """
        Converts boolean, datetime, and time attributes to their appropriate
        python types.  Assumes that all date/time attributes use the date
        format generated by Google forms.
        """
        _datetime_format = '%m/%d/%Y %H:%M:%S'
        attributes = {}
        for name in self.attribute_names:
            value = list_record[name].strip() if list_record[name] else ''
            field = self.schema_fields[name[:32]]
            if field.datatype == 'bool':
                if value.lower() == 'yes' or value.lower() == 'y':
                    value = True
                elif value.lower() == 'no' or value.lower() == 'n':
                    value = False
                else:
                    value = None
            elif field.datatype == 'time' or field.datatype == 'datetime':
                value = datetime.datetime.strptime(value, _datetime_format)
            attributes[name[:32]] = value
        return attributes

    def existing_record(self, record):
        qs = NewsItem.objects.filter(schema__id=self.schema.id)
        if qs.exists():
            for name in self.match_names:
                qs = qs.by_attribute(self.schema_fields[name], record[name])
            if qs.count() == 1:
                return qs.get()
        return None

    def list_pages(self):
        """Iterator that yields list pages as strings."""
        if not self._connected:
            raise GoogleScraperException('Not connected to an account.')
        yield self._client.GetListFeed(self.spreadsheet_id,
                self.worksheet_id).entry

    def parse_list(self, page):
        """
        Given a page, yields a dictionary of data for each record on the page.
        """
        for r in page:
            row = {}
            for key in r.custom.keys():
                row[key] = r.custom[key].text
            yield row
